{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d690122aa31f6af2e76d958c9b72209c12a46907"
   },
   "source": [
    "\n",
    "# Practical Assignment 1\n",
    "\n",
    "\n",
    "### [Bank Customer Churn Prediction](https://www.kaggle.com/kmalit/bank-customer-churn-prediction)\n",
    "by Keldine Malit, 2018.\n",
    "\n",
    "The objective of this notebook is to present an extensive analysis of a Customer Churn Dataset and to predict the customer churn rate. The first part of this notebook will focus on an exploration of the dataset and the other part will demonstrate different machine learning models for the prediction of churn.\n",
    "\n",
    "\n",
    "\n",
    "## Problem definition\n",
    "\n",
    "The aim of this study is to identify and visualize which factors contribute to customer churn, and then assess whether a model could be designed to do the following:\n",
    "1. Classify if a customer is going to churn or not, \n",
    "2. Choose a model, based on model performance, that will attach a probability to the churn to make it easier for customer service to target low hanging fruits in their efforts to prevent churn.\n",
    "\n",
    "**We will use this notebook as the framework for your assignment. There are portions of the notebook that will require no editing, however you will be required to edit certain portions in order to complete the assignment.**\n",
    "______\n",
    "\n",
    "## Goal of Assignment\n",
    "_______\n",
    "Your assignment is to identify and perform the following:\n",
    "\n",
    "**Question 1:** Which of the features is the most influential in ensuring an accurate classification? Provide a *detailed analysis* in the form of an EDA to justify your answer, and ensure that the sub-questions are answered appropriately.\n",
    "\n",
    "**Question 2:** Upon removing the feature you indentified in Question 1, which classification model is able to perform best? Provide a *detailed performance analysis* to justify your answer.\n",
    "_______\n",
    "\n",
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# data wrangling \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 1\n",
    "\n",
    "### Acquire data\n",
    "\n",
    "The Python Pandas packages helps us work with our datasets. We start by acquiring the dataset into Pandas DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data frame\n",
    "df = pd.read_csv('Churn_Modelling.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the data\n",
    "\n",
    "Identify the relevant features of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e46d6a276236ba04ec8cf1c3897c14a30d1ff754"
   },
   "source": [
    "The dataset has 1000 rows with 14 attributes. \n",
    "\n",
    "____\n",
    "\n",
    "**1.1 Which features are categorical?**\n",
    "\n",
    "These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, or binary? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "\n",
    "\n",
    "**1.2 Which features are numerical?**\n",
    "\n",
    "Which features are numerical? These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**1.3  Which features are mixed data types?**\n",
    "\n",
    "Numerical, alphanumeric data within same feature. These are candidates for correction.\n",
    "\n",
    "\n",
    "\n",
    "**1.4 Which features may contain errors or typos?**\n",
    "\n",
    "This is harder to review for a large dataset, however reviewing a few samples from a smaller dataset may just tell us outright, which features may require correcting.\n",
    "_______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "**1.5 Which features contain blank, null or empty values?**\n",
    "\n",
    "These will require correcting.\n",
    "\n",
    "\n",
    "\n",
    "**1.6 What are the data types for various features?**\n",
    "\n",
    "This helps us to know where conversions are needed.\n",
    "______\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "**1.7 What is the distribution of numerical feature values across the samples?**\n",
    "\n",
    "This helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "**1.8 What is the distribution of categorical features?**\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "\n",
    "Now we can continue confirming some of our assumptions using visualizations for analyzing the data.\n",
    "\n",
    "______________\n",
    "**1.9 Reassess the visualizations below, and add or remove as you see fit to provide a proper visual exploration.**\n",
    "_________\n",
    "\n",
    "### Correlating numerical features\n",
    "\n",
    "Let us start by understanding correlations between numerical features and our solution goal (Exited).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='Exited')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating numerical and ordinal features\n",
    "\n",
    "We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(df, col='Exited', row='IsActiveMember', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating categorical features\n",
    "\n",
    "Now we can correlate categorical features with our solution goal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "grid = sns.FacetGrid(df, row='Geography', size=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'IsActiveMember', 'Exited', 'Gender', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first review the 'Status' relation with categorical variables\n",
    "fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\n",
    "sns.countplot(x='Geography', hue = 'Exited',data = df, ax=axarr[0][0])\n",
    "sns.countplot(x='Gender', hue = 'Exited',data = df, ax=axarr[0][1])\n",
    "sns.countplot(x='HasCrCard', hue = 'Exited',data = df, ax=axarr[1][0])\n",
    "sns.countplot(x='IsActiveMember', hue = 'Exited',data = df, ax=axarr[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating categorical and numerical features\n",
    "\n",
    "We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Geography (Categorical non-numeric), Gender (Categorical non-numeric), Age (Numeric continuous), with Exited (Categorical numeric).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "grid = sns.FacetGrid(df, row='Geography', col='Exited', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Gender', 'Age', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relations based on the continuous data attributes\n",
    "fig, axarr = plt.subplots(3, 2, figsize=(20, 12))\n",
    "sns.boxplot(y='CreditScore',x = 'Exited', hue = 'Exited',data = df, ax=axarr[0][0])\n",
    "sns.boxplot(y='Age',x = 'Exited', hue = 'Exited',data = df , ax=axarr[0][1])\n",
    "sns.boxplot(y='Tenure',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][0])\n",
    "sns.boxplot(y='Balance',x = 'Exited', hue = 'Exited',data = df, ax=axarr[1][1])\n",
    "sns.boxplot(y='NumOfProducts',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][0])\n",
    "sns.boxplot(y='EstimatedSalary',x = 'Exited', hue = 'Exited',data = df, ax=axarr[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle data\n",
    "\n",
    "At this point your should have collected several assumptions and decisions regarding the datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\n",
    "\n",
    "### Correcting by dropping features\n",
    "\n",
    "This is a good starting goal to execute. By dropping features we are dealing with fewer data points, which speeds up our notebook and eases the analysis.\n",
    "\n",
    "Based on our assumptions and decisions we want to drop the features: RowNumber, CustomerId, and Surname.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a62bb5da5b4b6d4407bd0637c80a22c49bb1786"
   },
   "outputs": [],
   "source": [
    "# Check columns list and missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e98bb09ddde1439ea2dcdc0428d204a779fca9d"
   },
   "outputs": [],
   "source": [
    "# Get unique count for each variable\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b87b84346aca580e9b89ebdea888a4dfe217300"
   },
   "source": [
    "From the above, we will not require the first 2 attributes as the are specific to a customer. It is borderline with the surname as this would result to profiling so we exclude this as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cd50b315694153db48b27de69c168a88ac1d356"
   },
   "outputs": [],
   "source": [
    "# Drop the columns as explained above\n",
    "df = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88bde8bd630802a3daf982c6626dafaa0afd923a"
   },
   "outputs": [],
   "source": [
    "# Review the top rows of what is left of the data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45aef4b958a6648bbd4f7891e7acb0bc4a72e517"
   },
   "outputs": [],
   "source": [
    "# Check variable data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "170ef4a92a699333453cf6e18c42822303137db2"
   },
   "source": [
    "### Creating new feature extracting from existing\n",
    "We seek to add features that are likely to have an impact on the probability of churning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "296fb7912c926c64449c83d394ceaf1f5da3bde4"
   },
   "outputs": [],
   "source": [
    "df['BalanceSalaryRatio'] = df.Balance/df.EstimatedSalary\n",
    "sns.boxplot(y='BalanceSalaryRatio',x = 'Exited', hue = 'Exited',data = df)\n",
    "plt.ylim(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e13d0df114dbf1d6d9965e776403f4861380295"
   },
   "outputs": [],
   "source": [
    "# Given that tenure is a 'function' of age, we introduce a variable aiming to standardize tenure over age:\n",
    "df['TenureByAge'] = df.Tenure/(df.Age)\n",
    "sns.boxplot(y='TenureByAge',x = 'Exited', hue = 'Exited',data = df)\n",
    "plt.ylim(-1, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2444ab18fd23f562b2653e4a731a510b750cdfb"
   },
   "outputs": [],
   "source": [
    "'''Lastly we introduce a variable to capture credit score given age to take into account credit \n",
    "behaviour visavis adult life :-)'''\n",
    "df['CreditScoreGivenAge'] = df.CreditScore/(df.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54f01a2ae85f53e265700b712352a0b0fd62c689"
   },
   "outputs": [],
   "source": [
    "# Resulting Data Frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange columns by data type for easier manipulation\n",
    "continuous_vars = ['CreditScore',  'Age', 'Tenure', 'Balance','NumOfProducts', 'EstimatedSalary', 'BalanceSalaryRatio',\n",
    "                   'TenureByAge','CreditScoreGivenAge']\n",
    "cat_vars = ['HasCrCard', 'IsActiveMember','Geography', 'Gender']\n",
    "df = df[['Exited'] + continuous_vars + cat_vars]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf717510d96c68b996c12ab62ae7d25c45c6391a"
   },
   "source": [
    "### Converting categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d36171577f7377a9e6936481e454660c64367d1f"
   },
   "outputs": [],
   "source": [
    "'''For the one hot variables, we change 0 to -1 so that the models can capture a negative relation \n",
    "where the attribute in inapplicable instead of 0'''\n",
    "df.loc[df.HasCrCard == 0, 'HasCrCard'] = -1\n",
    "df.loc[df.IsActiveMember == 0, 'IsActiveMember'] = -1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cb7a887e800f644389f532de47d7a8f15ebed55"
   },
   "outputs": [],
   "source": [
    "# One hot encode the categorical variables\n",
    "lst = ['Geography', 'Gender']\n",
    "remove = list()\n",
    "for i in lst:\n",
    "    if (df[i].dtype == np.str or df[i].dtype == np.object):\n",
    "        for j in df[i].unique():\n",
    "            df[i+'_'+j] = np.where(df[i] == j,1,-1)\n",
    "        remove.append(i)\n",
    "df = df.drop(remove, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minMax scaling the continuous variables\n",
    "minVec = df[continuous_vars].min().copy()\n",
    "maxVec = df[continuous_vars].max().copy()\n",
    "df[continuous_vars] = (df[continuous_vars]-minVec)/(maxVec-minVec)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "______\n",
    "**Question 1.10:** Which of the features is the most influential in ensuring an accurate classification? Provide a detailed analysis in the form of an EDA to justify your answer. Below is some code you may use as part of your analysis of the data to assist with the argument you need to develop.\n",
    "\n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# QUESTION 2\n",
    "\n",
    "## Model and Predict\n",
    "\n",
    "Now we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Churned or not) with other variables or features (Age, Tenure, Balance...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN or k-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- Naive Bayes classifier\n",
    "- Decision Tree\n",
    "- Random Forrest\n",
    "- Perceptron\n",
    "- Artificial neural network\n",
    "- RVM or Relevance Vector Machine\n",
    "\n",
    "________\n",
    "\n",
    "**Question 2:**  Upon removing the feature you indentified in Question 1, as well as additional features you think are not relevant after your analysis, which classification model is able to perform best? Provide a detailed performance analysis to justify your answer. \n",
    "\n",
    "*Idea:* If you are able to I would suggest that you perform hyperparameter tuning where appropriate.\n",
    "____\n",
    "\n",
    "\n",
    "Let's set up our training and testing data sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train, test data\n",
    "df_train = df.sample(frac=0.8,random_state=200)\n",
    "df_test = df.drop(df_train.index)\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"Exited\"]\n",
    "X_train = df_train.drop([\"Exited\"], axis = 1)\n",
    "y_test = df_test[\"Exited\"]\n",
    "X_test = df_test.drop([\"Exited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = logreg.score(X_train, y_train) * 100\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we model using Support Vector Machines which are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of **two categories**, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc = round(svc.score(X_train, y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pattern recognition, the k-Nearest Neighbors algorithm (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest Neighbour\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "Y_pred = linear_svc.predict(X_test)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a decision tree as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "226779cf93f6ef4f5cc338d296139a2706ae33f7"
   },
   "source": [
    "### Model evaluation\n",
    "\n",
    "We can now rank our evaluation of all the models to choose the best one for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69748fd271b79bd41375f8168aa7245f0b24ed23"
   },
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
